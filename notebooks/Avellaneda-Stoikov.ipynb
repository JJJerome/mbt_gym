{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08005fcb",
   "metadata": {},
   "source": [
    "# Avellaneda-Stoikov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # my version of this notebook is in the subfolder \"notebooks\" of the repo\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, TD3\n",
    "import stable_baselines3\n",
    "\n",
    "from stochastic.processes.continuous import BrownianMotion, GeometricBrownianMotion, BesselProcess, BrownianBridge, BrownianMeander\n",
    "from stochastic.processes.diffusion import ConstantElasticityVarianceProcess\n",
    "\n",
    "from DRL4AMM.agents.Agent import Agent\n",
    "from DRL4AMM.agents.AvellanedaStoikovAgent import AvellanedaStoikovAgent\n",
    "from DRL4AMM.agents.BaselineAgents import RandomAgent, FixedSpreadAgent\n",
    "from DRL4AMM.agents.SBAgent import SBAgent\n",
    "from DRL4AMM.gym.ModelBasedEnvironment import ModelBasedEnvironment\n",
    "from DRL4AMM.gym.models import *\n",
    "from DRL4AMM.gym.AvellanedaStoikovEnvironment import AvellanedaStoikovEnvironment\n",
    "from DRL4AMM.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from DRL4AMM.gym.helpers.plotting import *\n",
    "from DRL4AMM.rewards.RewardFunctions import InventoryAdjustedPnL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fac6a3",
   "metadata": {},
   "source": [
    "## Random strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal_time = 1.0\n",
    "n_steps = 200\n",
    "seed = 42\n",
    "timestamps = np.linspace(0, terminal_time, n_steps + 1)\n",
    "\n",
    "as_env = AvellanedaStoikovEnvironment(terminal_time=terminal_time, n_steps=n_steps, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random = RandomAgent(as_env.action_space,seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c441b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(timestamps)\n",
    "as_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "as_env = AvellanedaStoikovEnvironment(terminal_time=terminal_time, n_steps=n_steps, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ee680",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "observations, actions, rewards = generate_trajectory(as_env,random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f809a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_as_trajectory(as_env, random, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454de9f5",
   "metadata": {},
   "source": [
    "## Fixed strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_spreads = [0.25,0.5,1,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ec44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_env.n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac996db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose\n",
    "isclose(0.999999999,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dict = {}\n",
    "\n",
    "for hs in half_spreads:\n",
    "    np.random.seed(42)\n",
    "    agent = FixedSpreadAgent(half_spread=hs)\n",
    "    performance_dict[hs] = {}\n",
    "    performance_dict[hs][\"observations\"], performance_dict[hs][\"actions\"], rewards = generate_trajectory(as_env,agent)\n",
    "    performance_dict[hs][\"cum_rewards\"] = np.cumsum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79896ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(performance_dict[hs][\"cum_rewards\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, figsize = (20,10))\n",
    "\n",
    "ax1.title.set_text(\"cum_rewards\")\n",
    "ax2.title.set_text(\"asset_prices\")\n",
    "ax3.title.set_text(\"inventory\")\n",
    "ax4.title.set_text(\"cash_holdings\")\n",
    "\n",
    "for hs in half_spreads:\n",
    "    ax1.plot(timestamps[1:],performance_dict[hs][\"cum_rewards\"], label = hs)\n",
    "    ax2.plot(timestamps,performance_dict[hs][\"observations\"][:,0], label = hs)\n",
    "    ax3.plot(timestamps,performance_dict[hs][\"observations\"][:,2], label = hs)\n",
    "    ax4.plot(timestamps,performance_dict[hs][\"observations\"][:,1], label = hs)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "ax4.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e3f0d",
   "metadata": {},
   "source": [
    "## Avellaneda-Stoikov Optimal Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c171a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 200\n",
    "as_agent = AvellanedaStoikovAgent(n_steps=N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, actions, rewards = generate_trajectory(as_env,as_agent)\n",
    "cum_rewards = np.cumsum(rewards)\n",
    "midprices=observations[:,0]\n",
    "bid_half_spreads, ask_half_spreads = actions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ae44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(midprices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cadf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_prices = midprices[1:] - bid_half_spreads\n",
    "ask_prices = midprices[1:] + ask_half_spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dac661",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2, figsize = (20,10))\n",
    "\n",
    "ax1.title.set_text(\"cum_rewards\")\n",
    "ax2.title.set_text(\"asset_prices\")\n",
    "ax3.title.set_text(\"inventory\")\n",
    "ax4.title.set_text(\"cash_holdings\")\n",
    "\n",
    "ax1.plot(cum_rewards)\n",
    "ax2.plot(midprices, label=\"midprice\")\n",
    "ax2.plot(bid_prices, label=\"quoted bid prices\")\n",
    "ax2.plot(ask_prices, label=\"quoted ask prices\")\n",
    "ax3.plot(observations[:,2])\n",
    "ax4.plot(observations[:,1])\n",
    "\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76675c",
   "metadata": {},
   "source": [
    "### Comparing the results to the Avellaneda Stoikov paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b71326",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, fig, _ = generate_results_table_and_hist(agent=as_agent,env=as_env,n_episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd8801",
   "metadata": {},
   "source": [
    "These results look similar to Table 2 of Avellaneda and Stoikov. It is interesting that the agent **does** quote a negative spread sometimes, which could be interpreted as taking liquidity but then the model should possibly be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26723547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b4c4b",
   "metadata": {},
   "source": [
    "## The effect of increasing risk aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e273095",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_aversions = [0.01,0.1,0.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ef0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards_dict = dict()\n",
    "for risk_aversion in risk_aversions:\n",
    "    agent = AvellanedaStoikovAgent(risk_aversion=risk_aversion)\n",
    "    _,_,total_rewards_dict[risk_aversion] = generate_results_table_and_hist(agent=agent,env=as_env,n_episodes=1000);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f20eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\", \"g\", \"b\", \"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(20,10))\n",
    "for risk_aversion, color in zip(risk_aversions,colors):\n",
    "    sns.histplot(total_rewards_dict[risk_aversion], label=f\"risk-aversion {risk_aversion}\", stat = \"density\", bins = 50, ax=ax, color=color)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eacfa0",
   "metadata": {},
   "source": [
    "**Note, it is hard to argue that the risk-averse agent is outperforming the non risk-averse agent in these cases...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a17018",
   "metadata": {},
   "source": [
    "### Training a stable baselines agent on the Avellaneda-Stoikov gym environment\n",
    "\n",
    "See separate notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
