{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08005fcb",
   "metadata": {},
   "source": [
    "# Cartea Jaimungal Penalva 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # This version of the notebook is in the subfolder \"notebooks\" of the repo\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from mbt_gym.agents.BaselineAgents import *\n",
    "from mbt_gym.gym.TradingEnvironment import TradingEnvironment\n",
    "from mbt_gym.gym.helpers.generate_trajectory import generate_trajectory\n",
    "from mbt_gym.gym.helpers.plotting import *\n",
    "from mbt_gym.stochastic_processes.midprice_models import *\n",
    "from mbt_gym.stochastic_processes.arrival_models import *\n",
    "from mbt_gym.stochastic_processes.fill_probability_models import *\n",
    "import torch\n",
    "#print(torch.cuda.is_available())\n",
    "#print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b5cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbt_gym.gym.ModelDynamics import LimitOrderModelDynamics\n",
    "from mbt_gym.rewards.RewardFunctions import CjMmCriterion\n",
    "seed = 410\n",
    "max_inventory = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(num_trajectories:int = 1,\n",
    "            initial_price = 100,\n",
    "            terminal_time = 1.0,\n",
    "            sigma = 2.0,\n",
    "            n_steps = 1000,\n",
    "            initial_inventory = 0,\n",
    "            arrival_rate = 140,\n",
    "            fill_exponent = 1.5,\n",
    "            per_step_inventory_aversion = 0.01,\n",
    "            terminal_inventory_aversion = 0.001):    \n",
    "    midprice_model = BrownianMotionMidpriceModel(initial_price = initial_price, \n",
    "                                                 volatility=sigma, step_size=terminal_time/n_steps,\n",
    "                                                 terminal_time = terminal_time,\n",
    "                                                 num_trajectories=num_trajectories)\n",
    "    arrival_model = PoissonArrivalModel(intensity=np.array([arrival_rate, arrival_rate]), \n",
    "                                        step_size=terminal_time/n_steps, \n",
    "                                        num_trajectories=num_trajectories)\n",
    "    fill_probability_model = ExponentialFillFunction(fill_exponent=fill_exponent, \n",
    "                                                     step_size=terminal_time/n_steps,\n",
    "                                                     num_trajectories=num_trajectories)\n",
    "    LOtrader = LimitOrderModelDynamics(midprice_model = midprice_model, arrival_model = arrival_model, \n",
    "                                fill_probability_model = fill_probability_model,\n",
    "                                num_trajectories = num_trajectories)\n",
    "    reward = CjMmCriterion(per_step_inventory_aversion = per_step_inventory_aversion,\n",
    "                           terminal_inventory_aversion = terminal_inventory_aversion,\n",
    "                           terminal_time = terminal_time)\n",
    "    env_params = dict(terminal_time=terminal_time, \n",
    "                      n_steps=n_steps,\n",
    "                      seed = seed,\n",
    "                      initial_inventory = initial_inventory,\n",
    "                      model_dynamics = LOtrader,\n",
    "                      reward_function = reward,\n",
    "                      max_inventory=max_inventory,\n",
    "                      normalise_action_space = False,\n",
    "                      normalise_observation_space = False,\n",
    "                      num_trajectories=num_trajectories)\n",
    "    return TradingEnvironment(**env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c171a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = get_env()\n",
    "agent = CarteaJaimungalMmAgent(env = env, max_inventory = max_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd86124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory(env, agent, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76675c",
   "metadata": {},
   "source": [
    "### Comparing the value function to the simulated optimal agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajectories = 1_000\n",
    "vec_env = get_env(num_trajectories)\n",
    "vec_agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea588e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations, actions, rewards = generate_trajectory(vec_env, vec_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b71326",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, fig, total_rewards = generate_results_table_and_hist(vec_env=vec_env,agent=vec_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e7174",
   "metadata": {},
   "source": [
    "# Value function versus total rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4aa92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()\n",
    "agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a766459",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rewards), np.std(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ed865",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))[0,0]\n",
    "sample_mean = np.mean(total_rewards)\n",
    "N = len(total_rewards)\n",
    "sample_variance = np.var(total_rewards) * N/(N-1)\n",
    "T = (sample_mean -  true_mean)/ (np.sqrt(sample_variance) / np.sqrt(N))\n",
    "q_l, q_u = scipy.stats.t(df=(N-1)).ppf((0.1, 0.9))\n",
    "if T>q_l and T<q_u:\n",
    "    print('We do not have evidence to reject the hypothesis that the means are not the same')\n",
    "else:\n",
    "    print('We have evidence to reject the hypothesis that the means are the same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5a0aa",
   "metadata": {},
   "source": [
    "# Alternative model parameters -- Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07cb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajectories = 1_000\n",
    "vec_env = get_env(num_trajectories, initial_price=150,\n",
    "                    terminal_time=1.0,\n",
    "                    sigma=1.0,\n",
    "                    n_steps=1000,\n",
    "                    initial_inventory=0,\n",
    "                    arrival_rate=100,\n",
    "                    fill_exponent=1.0)\n",
    "vec_agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "observations, actions, rewards = generate_trajectory(vec_env, vec_agent)\n",
    "results, fig, total_rewards = generate_results_table_and_hist(vec_env=vec_env,agent=vec_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()\n",
    "agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rewards), np.std(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))[0,0]\n",
    "sample_mean = np.mean(total_rewards)\n",
    "N = len(total_rewards)\n",
    "sample_variance = np.var(total_rewards) * N/(N-1)\n",
    "T = (sample_mean -  true_mean)/ (np.sqrt(sample_variance) / np.sqrt(N))\n",
    "q_l, q_u = scipy.stats.t(df=(N-1)).ppf((0.1, 0.9))\n",
    "if T>q_l and T<q_u:\n",
    "    print('We do not have evidence to reject the hypothesis that the means are the same')\n",
    "else:\n",
    "    print('We have evidence to reject the hypothesis that the means are the same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb2d03",
   "metadata": {},
   "source": [
    "# Alternative model parameters -- Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajectories = 1_000\n",
    "vec_env = get_env(num_trajectories, initial_price=50,\n",
    "                    terminal_time=1.0,\n",
    "                    sigma=1.5,\n",
    "                    n_steps=2000,\n",
    "                    initial_inventory=0,\n",
    "                    arrival_rate=50,\n",
    "                    fill_exponent=2.0)\n",
    "vec_agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "observations, actions, rewards = generate_trajectory(vec_env, vec_agent)\n",
    "results, fig, total_rewards = generate_results_table_and_hist(vec_env=vec_env,agent=vec_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()\n",
    "agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd209b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rewards), np.std(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))[0,0]\n",
    "sample_mean = np.mean(total_rewards)\n",
    "N = len(total_rewards)\n",
    "sample_variance = np.var(total_rewards) * N/(N-1)\n",
    "T = (sample_mean -  true_mean)/ (np.sqrt(sample_variance) / np.sqrt(N))\n",
    "q_l, q_u = scipy.stats.t(df=(N-1)).ppf((0.1, 0.9))\n",
    "if T>q_l and T<q_u:\n",
    "    print('We do not have evidence to reject the hypothesis that the means are the same')\n",
    "else:\n",
    "    print('We have evidence to reject the hypothesis that the means are the same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb49e1",
   "metadata": {},
   "source": [
    "# Alternative model parameters -- Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trajectories = 1_000\n",
    "vec_env = get_env(num_trajectories, initial_price=50,\n",
    "                    terminal_time=2.0,\n",
    "                    sigma=1.5,\n",
    "                    n_steps=2000,\n",
    "                    initial_inventory=0,\n",
    "                    arrival_rate=50,\n",
    "                    fill_exponent=2.0)\n",
    "vec_agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "#observations, actions, rewards = generate_trajectory(vec_env, vec_agent)\n",
    "results, fig, total_rewards = generate_results_table_and_hist(vec_env=vec_env,agent=vec_agent, n_episodes=num_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()\n",
    "agent = CarteaJaimungalMmAgent(env = vec_env, max_inventory = max_inventory)\n",
    "agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173819f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rewards), np.std(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc65816",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = agent.calculate_true_value_function(vec_env.state[0].reshape(1,-1))[0,0]\n",
    "sample_mean = np.mean(total_rewards)\n",
    "N = len(total_rewards)\n",
    "sample_variance = np.var(total_rewards) * N/(N-1)\n",
    "T = (sample_mean -  true_mean)/ (np.sqrt(sample_variance) / np.sqrt(N))\n",
    "q_l, q_u = scipy.stats.t(df=(N-1)).ppf((0.1, 0.9))\n",
    "if T>q_l and T<q_u:\n",
    "    print('We do not have evidence to reject the hypothesis that the means are the same')\n",
    "else:\n",
    "    print('We have evidence to reject the hypothesis that the means are the same')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "7fdb8041655b3dc02b7fba31b82b0328083461cc824a5f662da36f4ff301447b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
